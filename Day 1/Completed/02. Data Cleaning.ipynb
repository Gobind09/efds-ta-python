{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Let's load the 2021 data for AAPL this time. Unfortunately, this data is not quite as *clean* as the 2020 data, so we'll need to do some data wrangling. The file we're looking to load is `AAPL_2021_raw.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# New imports for a new notebook!\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Loading the data, setting the index, and having a look\n",
    "url = \"https://raw.githubusercontent.com/ImperialCollegeLondon/efds-ta-python/main/data/AAPL_2021_raw.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see what we mean by messy? How many issues can you spot?\n",
    "\n",
    "- Dates out of order\n",
    "- Duplicate rows\n",
    "- Missing values\n",
    "\n",
    "First let's start with sorting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Checking for ascending order in the index\n",
    "df.index.is_monotonic_increasing\n",
    "\n",
    "# Sorting the index in place\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's focus on duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Counting duplicates\n",
    "df.duplicated().sum()\n",
    "\n",
    "# Getting rid of duplicates\n",
    "df.drop_duplicates()\n",
    "\n",
    "# But make sure we update the variable to save our work!\n",
    "df\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Or we could have written:\n",
    "# df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the missing values next. Previously, we saw that `info()` gave us some insight into how many missing values we had, but we can also use `isnull()` combined with `sum()`, which contains a bit less noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've identified some missing values, the big question is how to handle them. There are many approaches to this that will vary depending on the data and the further analysis you plan to carry out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# We can just drop any row that contains NaN in any column\n",
    "df.dropna()\n",
    "\n",
    "# Drop a row which contains NaN in a specific column\n",
    "df.dropna(subset=\"Close\")\n",
    "\n",
    "# We can fill in NaNs with the average of a column\n",
    "df['Volume'].fillna(df['Volume'].mean())\n",
    "\n",
    "# We can interpolate (point on a line connecting the value of the days before and after)\n",
    "df[\"Adj Close\"].interpolate(method=\"linear\")\n",
    "\n",
    "# We can forward fill, and use the value from the day before\n",
    "df[\"Adj Close\"].ffill()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Notice how above we didn't update the variable or use `inplace`, so our DataFrame `df` is still full of missing values. Fix all missing values applying the following rules:\n",
    "- Interpolate missing values in the Close and Adj Close columns\n",
    "- Drop any rows with NaN in the Volume column\n",
    "- Forward fill missing values in the Open column\n",
    "\n",
    "Your DataFrame `df` should have no missing values when done. Use `info()` to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "todo"
    ]
   },
   "outputs": [],
   "source": [
    "## YOUR CODE GOES HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data\n",
    "\n",
    "Now that we've cleaned our data, let's save it, by writing it to a new .CSV file. We can use pandas' `to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"AAPL_2021_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
